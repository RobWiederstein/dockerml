@article{naz_deep_2020,
  title = {Deep Learning Approach for Diabetes Prediction Using {{PIMA Indian}} Dataset},
  author = {Naz, Huma and Ahuja, Sachin},
  year = {2020},
  month = apr,
  journal = {Journal of Diabetes and Metabolic Disorders},
  volume = {19},
  number = {1},
  pages = {391--403},
  issn = {2251-6581},
  doi = {10.1007/s40200-020-00520-5},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7270283/},
  urldate = {2025-05-10},
  abstract = {Purpose International Diabetes Federation (IDF) stated that 382 million people are living with diabetes worldwide. Over the last few years, the impact of diabetes has been increased drastically, which makes it a global threat. At present, Diabetes has steadily been listed in the top position as a major cause of death. The number of affected people will reach up to 629 million i.e. 48\% increase by 2045. However, diabetes is largely preventable and can be avoided by making lifestyle changes. These changes can also lower the chances of developing heart disease and cancer. So, there is a dire need for a prognosis tool that can help the doctors with early detection of the disease and hence can recommend the lifestyle changes required to stop the progression of the deadly disease. Method Diabetes if untreated may turn into fatal and directly or indirectly invites lot of other diseases such as heart attack, heart failure, brain stroke and many more. Therefore, early detection of diabetes is very significant so that timely action can be taken and the progression of the disease may be prevented to avoid further complications. Healthcare organizations accumulate huge amount of data including Electronic health records, images, omics data, and text but gaining knowledge and insight into the data remains a key challenge. The latest advances in Machine learning technologies can be applied for obtaining hidden patterns, which may diagnose diabetes at an early phase. This research paper presents a methodology for diabetes prediction using a diverse machine learning algorithm using the PIMA dataset. Results The accuracy achieved by functional classifiers Artificial Neural Network (ANN), Naive Bayes (NB), Decision Tree (DT) and Deep Learning (DL) lies within the range of 90--98\%. Among the four of them, DL provides the best results for diabetes onset with an accuracy rate of 98.07\% on the PIMA dataset. Hence, this proposed system provides an effective prognostic tool for healthcare officials. The results obtained can be used to develop a novel automatic prognosis tool that can be helpful in early detection of the disease. Conclusion The outcome of the study confirms that DL provides the best results with the most promising extracted features. DL achieves the accuracy of 98.07\% which can be used for further development of the automatic prognosis tool. The accuracy of the DL approach can further be enhanced by including the omics data for prediction of the onset of the disease.},
  pmcid = {PMC7270283},
  pmid = {32550190},
  file = {/Users/rkw/Zotero/storage/SNKW42WW/Naz and Ahuja - 2020 - Deep learning approach for diabetes prediction usi.pdf}
}

@article{nust_rockerverse_2020,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerisation}} with {{R}}},
  shorttitle = {The {{Rockerverse}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Dar{\'o}czi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Kjeldgaard, Lars and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and S{\'o}lymos, P{\'e}ter and Swetnam, Tyson Lee and Turaga, Nitesh and Petegem, Charlotte Van and Williams, Jason and Willis, Craig and Xiao, Nan},
  year = {2020},
  month = sep,
  journal = {The R Journal},
  volume = {12},
  number = {1},
  pages = {437--461},
  issn = {2073-4859},
  url = {https://rjournal.github.io/},
  urldate = {2025-04-29},
  abstract = {The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.},
  file = {/Users/rkw/Zotero/storage/ZC3KQINE/Nüst et al. - 2020 - The Rockerverse Packages and Applications for Con.pdf}
}

@article{nust_ten_2020,
  title = {Ten Simple Rules for Writing {{Dockerfiles}} for Reproducible Data Science},
  author = {N{\"u}st, Daniel and Sochat, Vanessa and Marwick, Ben and Eglen, Stephen J. and Head, Tim and Hirst, Tony and Evans, Benjamin D.},
  year = {2020},
  month = nov,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {11},
  pages = {e1008316},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008316},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008316},
  urldate = {2025-04-21},
  abstract = {Computational science has been greatly improved by the use of containers for packaging software and data dependencies. In a scholarly context, the main drivers for using these containers are transparency and support of reproducibility; in turn, a workflow's reproducibility can be greatly affected by the choices that are made with respect to building containers. In many cases, the build process for the container's image is created from instructions provided in a Dockerfile format. In support of this approach, we present a set of rules to help researchers write understandable Dockerfiles for typical data science workflows. By following the rules in this article, researchers can create containers suitable for sharing with fellow scientists, for including in scholarly communication such as education or scientific papers, and for effective and sustainable personal workflows.},
  langid = {english},
  keywords = {Computer and information sciences,Computer software,Habits,Metadata,Programming languages,Reproducibility,Software tools,Source code},
  file = {/Users/rkw/Zotero/storage/FFWL6ZWN/Nüst et al. - 2020 - Ten simple rules for writing Dockerfiles for repro.pdf}
}

@article{ostblom_opinionated_2021,
  title = {Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice},
  shorttitle = {Opinionated Practices for Teaching Reproducibility},
  author = {Ostblom, Joel and Timbers, Tiffany},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.13656 [cs, stat]},
  eprint = {2109.13656},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2109.13656},
  urldate = {2021-10-25},
  abstract = {In the data science courses at the University of British Columbia, we define data science as the study, development and practice of reproducible and auditable processes to obtain insight from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, for example predictive modelling, which is often one of the most interesting topic to novices. This fact, along with the highly technical nature of the industry standard reproducibility tools currently employed in data science, present out-of-the gate challenges in teaching reproducibility in the data science classroom. Put simply, students are not as intrinsically motivated to learn this topic, and it is not an easy one for them to learn. What can a data science educator do? Over several iterations of teaching courses focused on reproducible data science tools and workflows, we have found that providing extra motivation, guided instruction and lots of practice are key to effectively teaching this challenging, yet important subject. Here we present examples of how we deeply motivate, effectively guide and provide ample practice opportunities to data science students to effectively engage them in learning about this topic.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Statistics - Methodology},
  file = {/Users/rkw/Zotero/storage/V67YVGRQ/Ostblom_Timbers_2021_Opinionated practices for teaching reproducibility.pdf;/Users/rkw/Zotero/storage/IFHSGFC9/2109.html}
}

@article{perignon_computational_2024,
  title = {Computational {{Reproducibility}} in {{Finance}}: {{Evidence}} from 1,000 {{Tests}}},
  shorttitle = {Computational {{Reproducibility}} in {{Finance}}},
  author = {P{\'e}rignon, Christophe and Akmansoy, Olivier and Hurlin, Christophe and Dreber, Anna and Holzmeister, Felix and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Menkveld, Albert J and Razen, Michael and Weitzel, Utz},
  year = {2024},
  month = nov,
  journal = {The Review of Financial Studies},
  volume = {37},
  number = {11},
  pages = {3558--3593},
  issn = {0893-9454},
  doi = {10.1093/rfs/hhae029},
  url = {https://doi.org/10.1093/rfs/hhae029},
  urldate = {2025-05-10},
  abstract = {We analyze the computational reproducibility of more than 1,000 empirical answers to 6 research questions in finance provided by 168 research teams. Running the researchers' code on the same raw data regenerates exactly the same results only 52\% of the time. Reproducibility is higher for researchers with better coding skills and those exerting more effort. It is lower for more technical research questions, more complex code, and results lying in the tails of the distribution. Researchers exhibit overconfidence when assessing the reproducibility of their own research. We provide guidelines for finance researchers and discuss implementable reproducibility policies for academic journals.},
  file = {/Users/rkw/Zotero/storage/EZ6ZYSFP/Pérignon et al. - 2024 - Computational Reproducibility in Finance Evidence.pdf;/Users/rkw/Zotero/storage/7939AFL2/7697104.html}
}
