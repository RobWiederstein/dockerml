@article{nust_rockerverse_2020,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerisation}} with {{R}}},
  shorttitle = {The {{Rockerverse}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Dar{\'o}czi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Kjeldgaard, Lars and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and S{\'o}lymos, P{\'e}ter and Swetnam, Tyson Lee and Turaga, Nitesh and Petegem, Charlotte Van and Williams, Jason and Willis, Craig and Xiao, Nan},
  year = {2020},
  month = sep,
  journal = {The R Journal},
  volume = {12},
  number = {1},
  pages = {437--461},
  issn = {2073-4859},
  url = {https://rjournal.github.io/},
  urldate = {2025-04-29},
  abstract = {The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.},
  file = {/Users/rkw/Zotero/storage/ZC3KQINE/Nüst et al. - 2020 - The Rockerverse Packages and Applications for Con.pdf}
}

@article{nust_ten_2020,
  title = {Ten Simple Rules for Writing {{Dockerfiles}} for Reproducible Data Science},
  author = {N{\"u}st, Daniel and Sochat, Vanessa and Marwick, Ben and Eglen, Stephen J. and Head, Tim and Hirst, Tony and Evans, Benjamin D.},
  year = {2020},
  month = nov,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {11},
  pages = {e1008316},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008316},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008316},
  urldate = {2025-04-21},
  abstract = {Computational science has been greatly improved by the use of containers for packaging software and data dependencies. In a scholarly context, the main drivers for using these containers are transparency and support of reproducibility; in turn, a workflow's reproducibility can be greatly affected by the choices that are made with respect to building containers. In many cases, the build process for the container's image is created from instructions provided in a Dockerfile format. In support of this approach, we present a set of rules to help researchers write understandable Dockerfiles for typical data science workflows. By following the rules in this article, researchers can create containers suitable for sharing with fellow scientists, for including in scholarly communication such as education or scientific papers, and for effective and sustainable personal workflows.},
  langid = {english},
  keywords = {Computer and information sciences,Computer software,Habits,Metadata,Programming languages,Reproducibility,Software tools,Source code},
  file = {/Users/rkw/Zotero/storage/FFWL6ZWN/Nüst et al. - 2020 - Ten simple rules for writing Dockerfiles for repro.pdf}
}

@article{ostblom_opinionated_2021,
  title = {Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice},
  shorttitle = {Opinionated Practices for Teaching Reproducibility},
  author = {Ostblom, Joel and Timbers, Tiffany},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.13656 [cs, stat]},
  eprint = {2109.13656},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2109.13656},
  urldate = {2021-10-25},
  abstract = {In the data science courses at the University of British Columbia, we define data science as the study, development and practice of reproducible and auditable processes to obtain insight from data. While reproducibility is core to our definition, most data science learners enter the field with other aspects of data science in mind, for example predictive modelling, which is often one of the most interesting topic to novices. This fact, along with the highly technical nature of the industry standard reproducibility tools currently employed in data science, present out-of-the gate challenges in teaching reproducibility in the data science classroom. Put simply, students are not as intrinsically motivated to learn this topic, and it is not an easy one for them to learn. What can a data science educator do? Over several iterations of teaching courses focused on reproducible data science tools and workflows, we have found that providing extra motivation, guided instruction and lots of practice are key to effectively teaching this challenging, yet important subject. Here we present examples of how we deeply motivate, effectively guide and provide ample practice opportunities to data science students to effectively engage them in learning about this topic.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Statistics - Methodology},
  file = {/Users/rkw/Zotero/storage/V67YVGRQ/Ostblom_Timbers_2021_Opinionated practices for teaching reproducibility.pdf;/Users/rkw/Zotero/storage/IFHSGFC9/2109.html}
}

@article{perignon_computational_2024,
  title = {Computational {{Reproducibility}} in {{Finance}}: {{Evidence}} from 1,000 {{Tests}}},
  shorttitle = {Computational {{Reproducibility}} in {{Finance}}},
  author = {P{\'e}rignon, Christophe and Akmansoy, Olivier and Hurlin, Christophe and Dreber, Anna and Holzmeister, Felix and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Menkveld, Albert J and Razen, Michael and Weitzel, Utz},
  year = {2024},
  month = nov,
  journal = {The Review of Financial Studies},
  volume = {37},
  number = {11},
  pages = {3558--3593},
  issn = {0893-9454},
  doi = {10.1093/rfs/hhae029},
  url = {https://doi.org/10.1093/rfs/hhae029},
  urldate = {2025-05-10},
  abstract = {We analyze the computational reproducibility of more than 1,000 empirical answers to 6 research questions in finance provided by 168 research teams. Running the researchers' code on the same raw data regenerates exactly the same results only 52\% of the time. Reproducibility is higher for researchers with better coding skills and those exerting more effort. It is lower for more technical research questions, more complex code, and results lying in the tails of the distribution. Researchers exhibit overconfidence when assessing the reproducibility of their own research. We provide guidelines for finance researchers and discuss implementable reproducibility policies for academic journals.},
  file = {/Users/rkw/Zotero/storage/EZ6ZYSFP/Pérignon et al. - 2024 - Computational Reproducibility in Finance Evidence.pdf;/Users/rkw/Zotero/storage/7939AFL2/7697104.html}
}
